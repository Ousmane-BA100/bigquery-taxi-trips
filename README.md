üöÄ **Pipeline d'analyse m√©t√©o & Taxi NYC** üìä

üìù **Pr√©sentation du Projet**
Ce projet vise √† analyser l‚Äôimpact des conditions m√©t√©orologiques sur plus de 100‚ÄØ000‚ÄØ000 de courses de taxi √† New York. En exploitant un pipeline ELT sur GCP et une couche de visualisation Power BI, nous transformons des donn√©es brutes de trajets et de m√©t√©os en insights actionnables pour optimiser la r√©partition des taxis et anticiper les pics de demande.

## D√©mo du Tableau de Bord

![D√©monstration du tableau de bord](assets/screencast_dashboard.gif)


üîç **Caract√©ristiques du Jeu de Donn√©es**  
- **Sources** : NYC Taxi & Limousine Commission (trips CSV), Automated Observation System (AOS, m√©t√©o horaires)  
- **P√©riode** : historique mensuel sur plusieurs ann√©es  
- **Volume** : plus de 100‚ÄØmillions de courses et observations m√©t√©o pour plusieurs dizaines de stations

---

## Architecture du syst√®me
Le pipeline suit une architecture ELT robuste sur Google Cloud Platform (GCP) :

```
NYC.gov (trips CSV)  ‚îÄ‚îÄ‚îê
                       ‚îÇ
Weather API (AOS)   ‚îÄ‚îÄ>‚îÇ
                       ‚îÇ
                       v
                Airflow (Orchestration)
                       ‚îÇ
                       v
                GCS (Stockage brut)
                       ‚îÇ
                       v
               BigQuery (tables raw)
                       ‚îÇ
                       v
                    dbt (Transformation)
                       ‚îÇ
                       v
                BigQuery (tables marts)
                       ‚îÇ
                       v
                     Power BI
```


## Composants techniques

### √âtape 1 : Extract ‚Üí GCS  
- Harvest mensuel automatis√© des CSV taxi (NYC.gov) et m√©t√©o (AOS) via Airflow  
- Organisation et versioning des dizaines de Go de donn√©es dans GCS  
- Gestion des fichiers bruts avec un partitionnement efficace

### √âtape 2 : Load ‚Üí BigQuery  
- Ingestion dans deux tables **raw** : `trips` et `raw_weather_data`  
- Surveillance des √©checs d‚Äôingestion et gestion des doublons  
- Contr√¥les de qualit√© (format, compl√©tude)

### √âtape 3 : Staging avec dbt  
- **Nettoyage** : suppression des enregistrements incomplets ou aberrants  
- **Typage & conversions** : uniformisation des formats (timestamps, unit√©s, g√©olocation)  
- **Enrichissement** :  
  - Dimensions temporelles (heure, jour de semaine)  
  - Mapping g√©ographique : zone taxi ‚Üî station m√©t√©o  
- **Quality Gates** : tests automatiques (not_null, accepted_values) avant chaque ex√©cution

### √âtape 4 : Transform  
- Cr√©ation de tables **interm√©diaires** classifiant chaque course et observation m√©t√©o  
- Isolation des anomalies avant agr√©gations pour d√©tection pr√©coce des probl√®mes  
- **Marts sp√©cialis√©s** :  
  - **Data Quality** : suivi des anomalies  
  - **Full-Volume** : toutes courses pour analyses volum√©triques  
  - **Valid-Only** : courses valid√©es pour dashboards fiables  
  - **Fact Hourly** : historisation horaire avec 45+ m√©triques m√©t√©o  
  - **Agr√©gations** partitionn√©es par date, zone et condition m√©t√©o

### √âtape 5 : Visualisation  
- Strat√©gie **Import** vs **DirectQuery** selon les volum√©tries  
- Optimisation des requ√™tes BigQuery pour r√©duire la latence  
- Configuration Power BI (rapports, slicers, KPI) pour garantir fluidit√© et performance

---

## D√©fis techniques r√©solus

- **Asym√©trie des donn√©es** : courses au pas de minute vs m√©t√©o √† l‚Äôheure  
  **Solution** : partitionnement intelligent synchronisant fen√™tres temporelles course/m√©t√©o  
  **R√©sultat** : optimisation des temps de requ√™te et pr√©cision des analyses

- **Scalabilit√© & performance** :  
  - Tests automatiques √† chaque d√©ploiement  
  - Mod√®les incr√©mentaux avec partitionnement  
  - Macros dbt pour code r√©utilisable  
  **R√©sultat** : pipeline ELT modulable et performant sur GCP

## Contact  
Pour plus d'informations sur ce projet, veuillez me contacter sur LinkedIn : [Fran√ßois Vercellotti](https://www.linkedin.com/in/francois-vercellotti-3687492a8).

## Licence  
Ce projet est sous licence MIT.

